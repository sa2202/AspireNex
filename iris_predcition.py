# -*- coding: utf-8 -*-
"""IRIS_PREDCITION

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16EguHPTBU0YhkOq3vG2fts2_MP1kwrhl
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, classification_report, f1_score, confusion_matrix
from keras.models import Sequential
from keras.layers import Dense, Conv1D, Flatten, SimpleRNN, LSTM, Bidirectional
from keras.utils import to_categorical

file_path = '/content/IRIS.csv'
data = pd.read_csv(file_path)

data.head()

data.info()

data.columns

data.shape

data.describe()

data.dtypes

X = data.drop('species', axis=1)
y = data['species']

data["species"].value_counts()

encoder = LabelEncoder()
y_encoded = encoder.fit_transform(y)
y_categorical = to_categorical(y_encoded)

X.shape

y.shape

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

X_train, X_test, y_train, y_test = train_test_split(X_scaled,  y_categorical, test_size=0.3, random_state=42)

def evaluate_model(model, X_test, y_test, model_name):
    y_pred = model.predict(X_test)
    if model_name in ["CNN", "MLP", "RNN", "LSTM", "BiLSTM"]:
        y_pred_labels = encoder.inverse_transform(y_pred.argmax(axis=1))
        y_test_labels = encoder.inverse_transform(y_test.argmax(axis=1))
    else:
        y_pred_labels = encoder.inverse_transform(y_pred)
        y_test_labels = encoder.inverse_transform(y_test.argmax(axis=1))
    print(f"{model_name} Classification Report:")
    print(classification_report(y_test_labels, y_pred_labels))
    accuracy = accuracy_score(y_test_labels, y_pred_labels)
    f1 = f1_score(y_test_labels, y_pred_labels, average='weighted')
    # Plot confusion matrix
    conf_matrix = confusion_matrix(y_test_labels, y_pred_labels)
    plt.figure(figsize=(10, 7))
    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=encoder.classes_, yticklabels=encoder.classes_)
    plt.title(f"{model_name} Confusion Matrix")
    plt.xlabel("Predicted Labels")
    plt.ylabel("True Labels")
    plt.show()
    return accuracy, f1



cnn_model = Sequential()
cnn_model.add(Conv1D(32, kernel_size=2, activation='relu', input_shape=(X_train.shape[1], 1)))
cnn_model.add(Flatten())
cnn_model.add(Dense(3, activation='softmax'))

cnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
cnn_model.fit(X_train.reshape(-1, X_train.shape[1], 1), y_train, epochs=50, batch_size=10, validation_data=(X_test.reshape(-1, X_test.shape[1], 1), y_test))

cnn_accuracy, cnn_f1 = evaluate_model(cnn_model, X_test.reshape(-1, X_test.shape[1], 1), y_test, "CNN")

mlp_model = Sequential()
mlp_model.add(Dense(64, activation='relu', input_shape=(X_train.shape[1],)))
mlp_model.add(Dense(64, activation='relu'))
mlp_model.add(Dense(3, activation='softmax'))

mlp_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
mlp_model.fit(X_train, y_train, epochs=50, batch_size=10, validation_data=(X_test, y_test))

mlp_accuracy, mlp_f1 = evaluate_model(mlp_model, X_test, y_test, "MLP")

rnn_model = Sequential()
rnn_model.add(SimpleRNN(32, activation='relu', input_shape=(X_train.shape[1], 1)))
rnn_model.add(Dense(3, activation='softmax'))

rnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
rnn_model.fit(X_train.reshape(-1, X_train.shape[1], 1), y_train, epochs=50, batch_size=10, validation_data=(X_test.reshape(-1, X_test.shape[1], 1), y_test))

# Evaluate RNN Model
rnn_accuracy, rnn_f1 = evaluate_model(rnn_model, X_test.reshape(-1, X_test.shape[1], 1), y_test, "RNN")

# Train LSTM Model

lstm_model = Sequential()
lstm_model.add(LSTM(32, activation='relu', input_shape=(X_train.shape[1], 1)))
lstm_model.add(Dense(3, activation='softmax'))

lstm_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
lstm_model.fit(X_train.reshape(-1, X_train.shape[1], 1), y_train, epochs=50, batch_size=10, validation_data=(X_test.reshape(-1, X_test.shape[1], 1), y_test))

# Evaluate LSTM Model
lstm_accuracy, lstm_f1 = evaluate_model(lstm_model, X_test.reshape(-1, X_test.shape[1], 1), y_test, "LSTM")

bilstm_model = Sequential()
bilstm_model.add(Bidirectional(LSTM(32, activation='relu'), input_shape=(X_train.shape[1], 1)))
bilstm_model.add(Dense(3, activation='softmax'))

bilstm_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
bilstm_model.fit(X_train.reshape(-1, X_train.shape[1], 1), y_train, epochs=50, batch_size=10, validation_data=(X_test.reshape(-1, X_test.shape[1], 1), y_test))

# Evaluate BiLSTM Model
bilstm_accuracy, bilstm_f1 = evaluate_model(bilstm_model, X_test.reshape(-1, X_test.shape[1], 1), y_test, "BiLSTM")

print(X_train.shape)
print(X_test.shape)
print(y_train.shape)
print(y_test.shape)

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

from sklearn.preprocessing import LabelEncoder
label_encoder = LabelEncoder()
data["species"] = label_encoder.fit_transform(data['species'])

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state = 0)

print(X_train.shape)
print(X_test.shape)
print(y_train.shape)
print(y_test.shape)

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

from sklearn.linear_model import LogisticRegression
classifier = LogisticRegression(random_state = None)
classifier.fit(X_train, y_train)

from sklearn.metrics import confusion_matrix, accuracy_score, f1_score
y_pred = classifier.predict(X_test)
cm = confusion_matrix(y_test, y_pred)
print("The Confusion Matrix is : ")
print(cm)
acc_lr=accuracy_score(y_test, y_pred)
print(acc_lr)

f1_lr=f1_score(y_test, y_pred, average='weighted')
print(f1_lr)

from sklearn.neighbors import KNeighborsClassifier
classifier= KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)
classifier.fit(X_train, y_train)

from sklearn.metrics import confusion_matrix, accuracy_score, f1_score
y_pred = classifier.predict(X_test)
cm = confusion_matrix(y_test, y_pred)
print("The Confusion Matrix is : ")
print(cm)
acc_knn=accuracy_score(y_test, y_pred)
print(acc_knn)

f1_knn=f1_score(y_test, y_pred, average='weighted')
print(f1_knn)

from sklearn.naive_bayes import GaussianNB
classifier = GaussianNB()
classifier.fit(X_train, y_train)

from sklearn.metrics import confusion_matrix, accuracy_score, f1_score
y_pred = classifier.predict(X_test)
cm = confusion_matrix(y_test, y_pred)
print("The Confusion Matrix is : ")
print(cm)
acc_nb=accuracy_score(y_test, y_pred)
print(acc_nb)

f1_nb=f1_score(y_test, y_pred, average='weighted')
print(f1_nb)

from sklearn.ensemble import RandomForestClassifier
classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)
classifier.fit(X_train, y_train)

from sklearn.metrics import confusion_matrix, accuracy_score, f1_score
y_pred = classifier.predict(X_test)
cm = confusion_matrix(y_test, y_pred)
print("The Confusion Matrix is : ")
print(cm)
acc_rf=accuracy_score(y_test, y_pred)
print(acc_rf)

f1_rf=f1_score(y_test, y_pred, average='weighted')
print(f1_rf)

results = {
    "Model": ["CNN", "MLP", "RNN", "LSTM", "BiLSTM", "Random Forest", "Logistic Regression", "k-NN", "Gaussian"],
    "Accuracy": [cnn_accuracy, mlp_accuracy, rnn_accuracy, lstm_accuracy, bilstm_accuracy, acc_rf, acc_lr, acc_knn, acc_nb],
    "F1 Score": [cnn_f1, mlp_f1, rnn_f1, lstm_f1, bilstm_f1, f1_rf, f1_lr,f1_knn,f1_nb]
}
results_df = pd.DataFrame(results)
results_df = results_df.sort_values(by='Accuracy', ascending=True)
print(results_df)

